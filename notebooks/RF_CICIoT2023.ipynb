{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f7c50d-b0ae-4f19-9398-1435ba7a851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.style.use('dark_background')\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c40b5d2-727b-4f37-a480-9d46304eb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = 'CICIoT2023/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6854f877-5524-46ba-b7ca-5d6040015f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [04:33<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each CSV file and concatenate its contents to the DataFrame\n",
    "for csv_file in tqdm(df_sets):\n",
    "    file_path = os.path.join(DATASET_DIRECTORY, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2da890f-435f-4992-afd6-c5cb7a563041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flow_duration      14215577\n",
       "Header_Length      14215577\n",
       "Protocol Type      14215577\n",
       "Duration           14215577\n",
       "Rate               14215577\n",
       "Srate              14215577\n",
       "Drate              14215577\n",
       "fin_flag_number    14215577\n",
       "syn_flag_number    14215577\n",
       "rst_flag_number    14215577\n",
       "psh_flag_number    14215577\n",
       "ack_flag_number    14215577\n",
       "ece_flag_number    14215577\n",
       "cwr_flag_number    14215577\n",
       "ack_count          14215577\n",
       "syn_count          14215577\n",
       "fin_count          14215577\n",
       "urg_count          14215577\n",
       "rst_count          14215577\n",
       "HTTP               14215577\n",
       "HTTPS              14215577\n",
       "DNS                14215577\n",
       "Telnet             14215577\n",
       "SMTP               14215577\n",
       "SSH                14215577\n",
       "IRC                14215577\n",
       "TCP                14215577\n",
       "UDP                14215577\n",
       "DHCP               14215577\n",
       "ARP                14215577\n",
       "ICMP               14215577\n",
       "IPv                14215577\n",
       "LLC                14215577\n",
       "Tot sum            14215577\n",
       "Min                14215577\n",
       "Max                14215577\n",
       "AVG                14215577\n",
       "Std                14215577\n",
       "Tot size           14215577\n",
       "IAT                14215577\n",
       "Number             14215577\n",
       "Magnitue           14215577\n",
       "Radius             14215577\n",
       "Covariance         14215577\n",
       "Variance           14215577\n",
       "Weight             14215577\n",
       "label              14215577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the concatenated DataFrame\n",
    "df = concatenated_df.copy()\n",
    "print(concatenated_df.count())\n",
    "df.dropna(inplace=True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0433838d-ca57-4dd8-b41c-ad2ee3df61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "        'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "y_column = 'label'\n",
    "\n",
    "X_df = df[X_columns]\n",
    "y_df = df[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249673a6-4826-4b80-b9aa-dfa4c3d549c4",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38531da3-2cd7-4eb6-9514-9a4449d14660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "attack           13882317\n",
       "BenignTraffic      333260\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df_binary = y_df.apply(lambda x: 'attack' if x != 'BenignTraffic' else x)\n",
    "y_df_binary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba40f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_df = X_df.copy()\n",
    "for column in X_df.columns:\n",
    "    column_data = X_df[column].values.reshape(-1, 1)\n",
    "    scaled_df[column] = scaler.fit_transform(column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cde71fe-c5b1-4a55-8449-6b7a7048cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y_df_binary, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f7040c-177c-4862-9098-472402260509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 1453.221 seconds.\n"
     ]
    }
   ],
   "source": [
    "#Training a classifier\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier trained in {} seconds.\".format(round(tt, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eba0a77-88aa-4040-a693-01f810279920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier predicted on train set in 105.026 seconds.\n",
      "Classifier predicted on test set in 24.562 seconds.\n",
      "Accuracy train:  0.9999995603414248\n",
      "Accuracy test:  0.9976318236751508\n",
      "Precision:  0.9976318236751508\n",
      "Recall:  0.9976318236751508\n",
      "F1 Score:  0.9976318236751508\n"
     ]
    }
   ],
   "source": [
    "# Prediction on train set\n",
    "t0 = time()\n",
    "pred_train = clf.predict(X_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on train set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Prediction on test set\n",
    "t0 = time()\n",
    "pred_test = clf.predict(X_test)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on test set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_test, pred_test, average='micro')\n",
    "recall = recall_score(y_test, pred_test, average='micro')\n",
    "f1 = f1_score(y_test, pred_test, average='micro')\n",
    "accuracy_train = accuracy_score(y_train, pred_train)\n",
    "accuracy_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Printing results\n",
    "print(\"Accuracy train: \", accuracy_train)\n",
    "print(\"Accuracy test: \", accuracy_test)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60abc3f0-e32d-40be-abc5-fd5972cf9856",
   "metadata": {},
   "source": [
    "# Non-Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4846b0ed-cd5a-42c5-b58d-7c59e682fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d2c9144-bd0d-47dd-9db5-4a7386f26c7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tt \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier trained in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mround\u001b[39m(tt, \u001b[38;5;241m3\u001b[39m)))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training a classifier\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier trained in {} seconds.\".format(round(tt, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379900e8-8c41-4db3-8141-16658562d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "t0 = time()\n",
    "pred_train = clf.predict(X_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on train set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Prediction on test set\n",
    "t0 = time()\n",
    "pred_test = clf.predict(X_test)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on test set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_test, pred_test, average='micro')\n",
    "recall = recall_score(y_test, pred_test, average='micro')\n",
    "f1 = f1_score(y_test, pred_test, average='micro')\n",
    "accuracy_train = accuracy_score(y_train, pred_train)\n",
    "accuracy_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Printing results\n",
    "print(\"Accuracy train: \", accuracy_train)\n",
    "print(\"Accuracy test: \", accuracy_test)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a6df7-33db-44e6-8079-7a16f68c8e7a",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1440c39c-70bf-4152-b65a-afd9a337beb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pca \u001b[38;5;241m=\u001b[39m \u001b[43mPCA\u001b[49m()\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots( figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39mcumsum(pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA().fit(scaled_df)\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(15, 10))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Analysis for Digits Dataset')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Explained Variance')\n",
    "plt.legend()\n",
    "\n",
    "# Find the index where cumulative explained variance first exceeds 95%\n",
    "index_95_percent = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95)\n",
    "\n",
    "# Add a marker at the 95% point\n",
    "plt.scatter(index_95_percent, 0.95, color='r', marker='o')\n",
    "\n",
    "# Annotate the point with text\n",
    "plt.annotate(f'{index_95_percent+1} components\\n95% explained variance',\n",
    "             xy=(index_95_percent, 0.95), xytext=(index_95_percent+20, 0.92),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d277dd3-fe54-4fa5-805b-77ea23aea494",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=index_95_percent)\n",
    "pca_result = pca.fit_transform(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615dc9dd-6982-44a5-81df-69ed1ee944b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pca_result, y_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d428e-675e-41c8-bebe-421dbaa94c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on the test data\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "tt = time() - t0\n",
    "print (\"Trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b4857-4ec5-49af-adf8-27e3623a7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "t0 = time()\n",
    "pred_train = clf.predict(X_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on train set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Prediction on test set\n",
    "t0 = time()\n",
    "pred_test = clf.predict(X_test)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on test set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_test, pred_test, average='micro')\n",
    "recall = recall_score(y_test, pred_test, average='micro')\n",
    "f1 = f1_score(y_test, pred_test, average='micro')\n",
    "accuracy_train = accuracy_score(y_train, pred_train)\n",
    "accuracy_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Printing results\n",
    "print(\"Accuracy train: \", accuracy_train)\n",
    "print(\"Accuracy test: \", accuracy_test)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"Optimal number of components: \", index_95_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b331356-b3ef-4073-a063-210877beea00",
   "metadata": {},
   "source": [
    "# Selecting best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b610964-9f51-44b7-b8e3-d4596c655cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the labels and transform the column\n",
    "y_encoded = label_encoder.fit_transform(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e90be-43a2-4c27-aa84-98b12a116321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of percentiles to test\n",
    "percentiles = [10, 20, 30, 40, 50]\n",
    "\n",
    "# Create a pipeline with feature selection and your classifier\n",
    "model = make_pipeline(SelectPercentile(score_func=f_classif), RandomForestClassifier())\n",
    "\n",
    "# Store accuracies for each percentile\n",
    "accuracies = []\n",
    "\n",
    "# Perform cross-validation for each percentile\n",
    "for percentile in tqdm(percentiles):\n",
    "    model.set_params(selectpercentile__percentile=percentile)\n",
    "    scores = cross_val_score(model, scaled_df, y_encoded, cv=5)\n",
    "    accuracies.append(scores.mean())\n",
    "\n",
    "# Print accuracies for each percentile\n",
    "for percentile, accuracy in zip(percentiles, accuracies):\n",
    "    print(f\"Percentile: {percentile}, Mean Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea354f-fb75-4ec1-9a32-2d36164777bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(score_func=f_classif, percentile=30)\n",
    "\n",
    "# Fit and transform the training set\n",
    "X_selected = selector.fit_transform(scaled_df, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48d92c-35cb-4b66-93ab-650e7347ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987cd2eb-bee0-4ed2-80ee-5bce25f33f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on the test data\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "tt = time() - t0\n",
    "print (\"Trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad7c7a-defb-419d-b0fc-60a771042d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "t0 = time()\n",
    "pred_train = clf.predict(X_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on train set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Prediction on test set\n",
    "t0 = time()\n",
    "pred_test = clf.predict(X_test)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on test set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_test, pred_test, average='micro')\n",
    "recall = recall_score(y_test, pred_test, average='micro')\n",
    "f1 = f1_score(y_test, pred_test, average='micro')\n",
    "accuracy_train = accuracy_score(y_train, pred_train)\n",
    "accuracy_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Printing results\n",
    "print(\"Accuracy train: \", accuracy_train)\n",
    "print(\"Accuracy test: \", accuracy_test)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"% feature selected\", optimal_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2b31d-95d6-4b96-a474-0c48a39a7d76",
   "metadata": {},
   "source": [
    "# RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2c3e7-a020-4a5c-8814-b79c75613fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select at least 10% of the features\n",
    "num_columns = len(kdd_df.columns)\n",
    "min_features_to_select = int(num_columns * 0.1)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    step=4,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    n_jobs=2,\n",
    ")\n",
    "rfecv.fit(features, labels)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0f786-c873-497e-b0b3-263600132375",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices = rfecv.support_\n",
    "selected_feature_names = [num_features[i] for i, selected in enumerate(selected_feature_indices) if selected]\n",
    "\n",
    "print(\"Selected Features:\", selected_feature_names)\n",
    "\n",
    "reduced_df = features[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc491f-03cd-4cc6-92a3-7ce7cdadfaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training set\n",
    "#X_selected = selector.fit_transform(reduced_df, labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced_df, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5affbc-a11f-4f33-8c43-fc58a19129f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on the test data\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "tt = time() - t0\n",
    "print (\"Trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a47816-85c9-4160-8c45-739190af8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "t0 = time()\n",
    "pred_train = clf.predict(X_train)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on train set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Prediction on test set\n",
    "t0 = time()\n",
    "pred_test = clf.predict(X_test)\n",
    "tt = time() - t0\n",
    "print (\"Classifier predicted on test set in {} seconds.\".format(round(tt, 3)))\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_test, pred_test, average='micro')\n",
    "recall = recall_score(y_test, pred_test, average='micro')\n",
    "f1 = f1_score(y_test, pred_test, average='micro')\n",
    "accuracy_train = accuracy_score(y_train, pred_train)\n",
    "accuracy_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Printing results\n",
    "print(\"Accuracy train: \", accuracy_train)\n",
    "print(\"Accuracy test: \", accuracy_test)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"N features selected\", len(reduced_df.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
